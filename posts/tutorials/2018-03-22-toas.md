---
layout: page
type: tutorial
title: Making TOAs
hide: true
permalink: tutorials/toas
---

A time of arrival (TOA) is the key component of a pulsar's timing solution; it is the raw data point to which the timing solution model is fit. A time of arrival can be thought of as a "timestamp" indicating when the radiation from a pulsar arrived at the telescope with which we are observing. The time of arrival is not the true arrival time of any single pulse of a radiation from a pulsar, but rather it is a "timestamp" associated with the averaged data from a single observation at a single frequency. Even though we may observe a pulsar for tens or minutes or even 1 - 2 hours and at a wide range of frequencies, we average all of this data together in order to produce just a few TOAs for a single observation. For example, we may observe a pulsar for 1 hour over frequencies ranging from 33 MHz to 78 Mhz, but only produce 2 TOAs from this observation: 1 TOA for the first 30 minutes of the observation and 1 TOA for the second 30 minutes of the observation, both with an associated frequency which is the central frequency of our observation band (55.5 MHz). Of course, we can divy up our observation into smaller chuncks in time, producing more TOAs at different times for a single observation. We can also divy up our frequency band in a finer-grained manner, producing TOAs at several different frequencies for a single observation instead of just 1 characteristic frequency.

## Scrunching Data with `pam`

The process of averaging together data in time and frequency is known in our jargon as "scrunching" the data. We can scrunch in both the time domain and the frequency domain. Raw pulsar observation data stored in the standard psrchive **INSERT LINK** format (`.ar` files) can be scrunched using the pam command **INSERT LINK** from psrchive. `pam` is a general purpose tool for modifying `.ar` files. In our use, we will use it to simply scrunch data in the time and frequency domains using the following commands:
```bash
pam -e <ext> --nsubint=<num_sub_integrations> <ar_file>
```
and
```bash
pam -e <ext> --nsubchn=<num_frequency_channels> <ar_file>
```
When writing code, whenever we surround a word with brackets (`<>`), we mean that you have to replace what's inside the brackets with the object described in the brackets. For example, here we would replace `<ar_file>` with `my_pulsar_data.ar`, which is just a standard `.ar` file. `<num_sub_integrations>` is replaced with the desired number of sub integrations that you want your data to be segmented into. For example, if our observation is an hour long and we use 2 for the number of sub integrations, at the end of the scrunch, our data will be averaged into two 30 minute sections. Similarly, using 4 would average the data into four 15 minute sections. `<num_frequency_channels>` is replaced with the number of frequency channels to segment the data into. Usually, our data from the telescope, once processed, is very finely grained, containing information about the pulsar at several hundred or several thousands of frequencies in our observing band. We can average this data together in the frequency domain, so that we have averaged data that is associated with only `<num_frequency_channels>` number of channels. For example, averaging down to 2 frequency channels on data that covers the frequency range of 20 MHz - 100 MHz would produce data that is associated with frequencies of 40 MHz and 80 MHz (these two frequencies are the center frequencies between 20 MHz - 60 MHz and 60 MHz - 100 MHz, where 60 MHz is the halfway point between 20 and 100). Finally, `<ext>` provides an extension to use to append to the data files when writing them back out into files. Usually, we want to differentiate the scrunched files from the raw `.ar` files, so we use the conventiion of putting how many sub integrations and how many frequency channels are in the scrunched data in the extension. For example, if we scrunched our data down to 2 sub integrations and 2 frequency channels we might use `<ext> = 2sub2chan` to indicate to us and others the properties of the scrunched data. But you can use whatever makes sense to you.


`pam` has the ability to operate on many `.ar` files at once, and you can provide it with all of the `.ar` files in your current directory using
```bash
pam -e <ext> --nsubint=<num_sub_integrations> --nsubchn=<num_frequency_channels> *.ar
```

## What scrunched data looks like

The purpose of scrunching data is to average together low signal-to-noise ratio (SNR) pulse profiles together to produce one high SNR pulse profile. We can see this effect by using psrplot to examine the `.ar` files before the scrunching and after the scrunching. For convenience, we will use the `summary_plot` command to plot the `.ar` data.

First, we will examine some data from the pulsar **INSERT PULSAR**. The raw ar files used can be found here: **INSERT LINK** 

```bash
summary_plot <ar_file>.ar
```

**INSERT PICTURES HERE**

Next, we will scrunch the data using `pam`:
```bash
pam -e 2sub2chan --nsubint=2 --numchn=2 <ar_file>.ar
```

Finally, we will observe this scrunched data using
```bash
summary_plot <file>.2sub2chan
```

## Making TOAs

Making a TOA involves matching a template (what we think the pulse profile looks like) to our pulse profile, which we saw in the section above. Template matching is a process by which a template is swept through a set of data (usually a time series) and the location where the template best matches the data is found. By sweeping a template over the pulse profile and then finding the point in time where the template best matches the data, we are making a high precision measurement of the time of arrival of the *averaged* pulsar signal for our observation. This template matching can be performed using the command `pat` **INSERT LINK** from the psrchive software. `pat` is used as follows
```bash
pat -f princeton -F -s <template_location> > <outfilename>
```
The `-f princeton` tells `pat` to print out the TOAs using the princeton format. There are several formats available, but the princeton format is the simplest and most straightforward to use. The `-F` tells `pat` to also average the data in polarization as well. The `-s <template_location>` tells `pat` to look for a template at the location `<template_location>`. Finally the `> <outfilename>` tells Bash to pipe the output of `pat` (the TOAs) into a file called `<outfilename>`. For example, using the scrunched data from above we can use the command
```bash
pat -f princeton -F -s PULSAR_TEMPLATE > PULSAR_NAME.tim
```
to construct TOAs for this pulsar at the times and frequencies associated with the scrunched data. If we inspect the file `PULSAR_NAME.tim`, we will see that it's just a bunch of text:
```
TEXT
```
Describe the output from the TOAs

## Evaluating TOAs

How do you know if your TOAs are any good? Are you sure that the pulsar signal is actually in your date? To check this, we want to consider two things: the template matching procedure ensures that the uncertainty on a TOA should be ~1000 times less than the pulse period of the pulsar. For example, if you have a slow pulsar with a spin period of ~ 1 s, you would expect that the typical TOA will have an uncertainty associated with it of ~ 1 ms. This is why millisecond pulsars (fast pulsars) are valuable tools, because the process of TOA creation creates extremely precise TOAs; with a spin period of ~ 1 ms, a millisecond pulsar will have typical TOAs with uncertainties of ~ 1 $$ \micro s $$. This is what pulsar astronomers usually mean when they mean that millisecond pulsars are good timers (they are also usually talking about the stability of the pulsar as well).

Another check for whether TOAs are good or not is to check whether they are consistent with a previous timing solution for the pulsar. This gets a bit tricky if the timing solution for the pulsar has not been developed yet. Timing is discussed in another post [here](timing.html).

